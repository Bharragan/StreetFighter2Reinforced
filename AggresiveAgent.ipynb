{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\jose_\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (0.21.0)\n",
      "Requirement already satisfied: gym-retro in c:\\users\\jose_\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (0.8.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\jose_\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from gym) (1.24.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\jose_\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from gym) (3.0.0)\n",
      "Requirement already satisfied: pyglet==1.*,>=1.3.2 in c:\\users\\jose_\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from gym-retro) (1.5.29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\jose_\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install gym gym-retro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing retro to play Street Fighter using a ROM\n",
    "import retro\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing StreetFighterIISpecialChampionEdition-Genesis\n",
      "Importing StreetFighterIISpecialChampionEdition-Genesis\n",
      "Imported 2 games\n"
     ]
    }
   ],
   "source": [
    "!python -m retro.import ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an environment for Street Fighter\n",
    "env = retro.make(game='StreetFighterIISpecialChampionEdition-Genesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing the environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0], dtype=int8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample actions that are possible in the environment\n",
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'sleep'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m env\u001b[38;5;241m.\u001b[39mrender()\n\u001b[0;32m     11\u001b[0m obs, reward, done, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample())\n\u001b[1;32m---> 12\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(reward)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'sleep'"
     ]
    }
   ],
   "source": [
    "# Reset game to stating state\n",
    "obs = env.reset()\n",
    "# Set flag to false\n",
    "done = False\n",
    "\n",
    "for game in range(1):\n",
    "    while not done:\n",
    "        if done:\n",
    "            obs = env.reset()\n",
    "        env.render()\n",
    "        obs, reward, done, info = env.step(env.action_space.sample())\n",
    "        time.sleep(0.01)\n",
    "        print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 60.0}\n"
     ]
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.10.0.82-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\jose_\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from opencv-python) (1.24.3)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\jose_\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import Env\n",
    "from gym.spaces import MultiBinary, Box\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreetFighterEnv(Env):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.observation_space = Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8)\n",
    "        self.action_space = MultiBinary(12)\n",
    "        self.game = retro.make(game='StreetFighterIISpecialChampionEdition-Genesis', use_restricted_actions=retro.Actions.FILTERED)\n",
    "        self.previous_frame = None\n",
    "        self.score = 0\n",
    "        self.previous_health = None\n",
    "        self.opponent_previous_health = None\n",
    "        self.action_history = []\n",
    "\n",
    "    def reset(self):\n",
    "        obs = self.game.reset()\n",
    "        obs = self.preprocess(obs)\n",
    "        self.previous_frame = obs\n",
    "        self.score = 0\n",
    "        self.previous_health = 176\n",
    "        self.opponent_previous_health = 176\n",
    "        self.action_history = []\n",
    "        return obs\n",
    "\n",
    "    def preprocess(self, observation):\n",
    "        gray = cv2.cvtColor(observation, cv2.COLOR_BGR2GRAY)\n",
    "        resize = cv2.resize(gray, (84, 84), interpolation=cv2.INTER_CUBIC)\n",
    "        channels = np.reshape(resize, (84, 84, 1))\n",
    "        return channels\n",
    "\n",
    "    def step(self, action):\n",
    "        if len(self.action_history) >= 5 and all(np.array_equal(a, action) for a in self.action_history[-5:]):\n",
    "            action = self.action_space.sample()\n",
    "\n",
    "        self.action_history.append(action)\n",
    "        if len(self.action_history) > 10:\n",
    "            self.action_history.pop(0)\n",
    "\n",
    "        obs, reward, done, info = self.game.step(action)\n",
    "        obs = self.preprocess(obs)\n",
    "        frame_delta = obs - self.previous_frame\n",
    "        self.previous_frame = obs\n",
    "\n",
    "        current_health = info.get('health', self.previous_health)\n",
    "        opponent_current_health = info.get('enemy_health', self.opponent_previous_health)\n",
    "\n",
    "        reward = 0\n",
    "        if current_health < self.previous_health:\n",
    "            reward -= (self.previous_health - current_health) * 0.05  # Reduced penalty for receiving damage\n",
    "        if opponent_current_health < self.opponent_previous_health:\n",
    "            reward += (self.opponent_previous_health - opponent_current_health) * 0.2  # Increased reward for hitting\n",
    "\n",
    "        if done:\n",
    "            if opponent_current_health <= 0:\n",
    "                reward += 500  # Increased reward for winning\n",
    "            else:\n",
    "                reward -= 50  # Reduced penalty for losing\n",
    "\n",
    "        self.previous_health = current_health\n",
    "        self.opponent_previous_health = opponent_current_health\n",
    "\n",
    "        return frame_delta, reward, done, info\n",
    "\n",
    "    def render(self, *args, **kwargs):\n",
    "        self.game.render()\n",
    "\n",
    "    def close(self):\n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from collections import deque\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_shape, num_actions):\n",
    "        self.state_shape = state_shape\n",
    "        self.num_actions = num_actions\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.1\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = tf.keras.Sequential([\n",
    "            layers.Conv2D(32, (8, 8), strides=(4, 4), activation='relu', input_shape=self.state_shape),\n",
    "            layers.Conv2D(64, (4, 4), strides=(2, 2), activation='relu'),\n",
    "            layers.Conv2D(64, (3, 3), strides=(1, 1), activation='relu'),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(512, activation='relu'),\n",
    "            layers.Dense(self.num_actions, activation='linear')\n",
    "        ])\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(lr=self.learning_rate), loss='mse')\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.num_actions)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, verbose=0)  # Aquí se aplica verbose=0 para no imprimir\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)\n",
    "\n",
    "    def map_action(self, action_index):\n",
    "        action = np.zeros(self.num_actions, dtype=int)\n",
    "        action[action_index] = 1\n",
    "        return action\n",
    "\n",
    "# Entrenamiento del agente\n",
    "env = StreetFighter()\n",
    "agent = DQNAgent(state_shape=(84, 84, 1), num_actions=env.action_space.shape[0])\n",
    "episodes = 5000000  # Cambiar según sea necesario\n",
    "\n",
    "for e in range(episodes):\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, 84, 84, 1])\n",
    "    for time in range(5000):  # Se podría ajustar el número de pasos máximo por episodio\n",
    "        action_index = agent.act(state)\n",
    "        action = agent.map_action(action_index)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        next_state = np.reshape(next_state, [1, 84, 84, 1])\n",
    "        agent.remember(state, action_index, reward, next_state, done)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(f\"episode: {e}/{episodes}, score: {time}, e: {agent.epsilon:.2}\")\n",
    "            break\n",
    "    if len(agent.memory) > 32:\n",
    "        agent.replay(32)\n",
    "\n",
    "    if (e + 1) % 100000 == 0:  # Guardar el modelo cada 100,000 episodios\n",
    "        agent.save(f\"model_{e+1}.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
